\documentclass[onecolumn, draftclsnofoot,10pt, compsoc]{IEEEtran}
\usepackage{graphicx}
\usepackage{url}
\usepackage{pgfgantt}
\usepackage{setspace}

\usepackage{geometry}
\geometry{textheight=9.5in, textwidth=7in}

% 1. Fill in these details
\def \CapstoneTeamName{		The Seed Team}
\def \CapstoneTeamNumber{		32}
\def \GroupMemberOne{			Bharath Padmaraju}
\def \GroupMemberTwo{			Kevin Deming}
\def \GroupMemberThree{			Haoxuan Zhan}
\def \GroupMemberFour{			Cong Yang}
\def \GroupMemberFive{			Christopher Wohlwend}
\def \CapstoneProjectName{		Pure Grass Seed Sorter}
\def \CapstoneSponsorCompany{	Oregon State University Seed Lab}
\def \CapstoneSponsorPerson{		Dan Curry}

% 2. Uncomment the appropriate line below so that the document type works
\def \DocType{		Requirement Document
				%Requirements Document
				%Technology Review
				%Design Document
				%Progress Report
				}
			
\newcommand{\NameSigPair}[1]{\par
\makebox[2.75in][r]{#1} \hfil 	\makebox[3.25in]{\makebox[2.25in]{\hrulefill} \hfill		\makebox[.75in]{\hrulefill}}
\par\vspace{-12pt} \textit{\tiny\noindent
\makebox[2.75in]{} \hfil		\makebox[3.25in]{\makebox[2.25in][r]{Signature} \hfill	\makebox[.75in][r]{Date}}}}
% 3. If the document is not to be signed, uncomment the RENEWcommand below
%\renewcommand{\NameSigPair}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\begin{titlepage}
    \pagenumbering{gobble}
    \begin{singlespace}
    	\includegraphics[height=4cm]{coe_v_spot1}
        \hfill 
        % 4. If you have a logo, use this includegraphics command to put it on the coversheet.
        %\includegraphics[height=4cm]{CompanyLogo}   
        \par\vspace{.2in}
        \centering
        \scshape{
            \huge CS Capstone \DocType \par
            {\large\today}\par
            \vspace{.5in}
            \textbf{\Huge\CapstoneProjectName}\par
            \vfill
            {\large Prepared for}\par
            \Huge \CapstoneSponsorCompany\par
            \vspace{5pt}
            {\Large\NameSigPair{\CapstoneSponsorPerson}\par}
            {\large Prepared by }\par
            Group\CapstoneTeamNumber\par
            % 5. comment out the line below this one if you do not wish to name your team
            \CapstoneTeamName\par 
            \vspace{5pt}
            {\Large
                \NameSigPair{\GroupMemberOne}\par
                \NameSigPair{\GroupMemberTwo}\par
                \NameSigPair{\GroupMemberThree}\par
                \NameSigPair{\GroupMemberFour}\par
                \NameSigPair{\GroupMemberFive}\par
            }
            \vspace{20pt}
        }
        \begin{abstract}
        % 6. Fill in your abstract    
        	The primary objective of the project is to automate grass seed sorting. The members of the group will be building software to be able to discriminate between pure grass seeds from all other plant seeds including but not limited to weeds, and crop seeds. The method we will utilize will be a combination of implementing computer vision and deep learning algorithms to accurately identify off type seeds under a high definition camera. This will vastly reduce the stress and workload imposed upon seed analysts, and likely speed up the sorting process. Not only does this project offer a opportunity to improve seed research, but also creates possibilities in other fields where our technology can automate menial and repetitive tasks.
        \end{abstract}     
    \end{singlespace}
\end{titlepage}
\newpage
\pagenumbering{arabic}
\tableofcontents
% 7. uncomment this (if applicable). Consider adding a page break.
%\listoffigures
%\listoftables
\clearpage

% 8. now you write!
\section{Introduction}

\subsection{Purpose}
The purpose of this document is to describe and explain the requirements of the computer vision grass seed sorter project in detail. The paper will inform readers about the technologies that will be used in the project and how they relate to the final system, we will also be discussing the work flow we plan to implement. Moreover, we will discuss the interface that the users will be able to control and toggle to reach the desired outcome of the project.   

\subsection{Scope}
The computer vision grass seed sorter uses a neural network classifier to allow a computer system to discriminate off-type seeds from samples instead of relying manual labor. The project will stretch beyond software and will potentially require collaboration with the mechanical engineering capstone team to incorporate the software with the physical robot. After the project is done, it will be delivered to Oregon State University Seed Lab. 

\subsection{Product Overview}

\subsubsection{Product Perspective}
According to Oregon State University Seed Lab, research assistants have to spend countless hours doing the monotonous task of looking at an assembly line of seeds and keeping an eye out for off-type ones. Sorting the seeds is inefficient this way as concentration of the assistants varies and affects results. Our products provide a much faster way to sort seeds efficiently with a higher detection rate.

\subsubsection{Product Functions}
Using a high resolution camera, a computer vision pre-processor, and deep learning algorithms, our product will discriminate pure seed from all other weed seeds, crop seeds and other plant material. After going through our system, pure seeds and others are separated into smaller batches that assistants can use to verify afterwords. 

\subsubsection{User Characteristics}
Our users are the assistants themselves who will setup our easily portable system and understand how to maintain it using our documentation. The users won't have to continuously monitor the system, only every once in a while if an error occurs or the system needs to be rebooted.

\subsubsection{Limitations}
Due to the constant standard of sorting is set up, sorting seeds with different complexity will result in different ranges of detection rate. According to International Seed Testing Machine Sorting Minimums, the minimum detection rate of easy, medium and difficult seeds are corresponding 98\%, 88\% and 62\%. Our product may not sort seeds with a high detection rate when we are discriminating from the pure seeds and seeds with only one or few criteria that can be identified.

\subsection{Definitions}
Neural network: The neural network is a matrix that is trained using a deep learning algorithm. \\
Test sample: Our test sample contains 25,000 seeds. \\
Target seed: It is the seed we want from test sample. \\
Purity: The authenticity of the target seed. \\
Off-type seed: The seeds we wish to distinguish from the target seed. \\
Webcam : A plug and play small scale high definition camera that is lightweight portable. 


\section{References}
[1] “C920 HD Pro Webcam,” Logitech C920 PRO HD Webcam, 1080p Video with Stereo Audio. [Online]. Available: https://www.logitech.com/en-us/product/hd-pro-webcam-c920#specification-tabular. [Accessed: 31-Oct-2018]. \newline
[2] “Convolutional neural network,” Wikipedia, 28-Oct-2018. [Online]. Available: https://en.wikipedia.org/wiki/Convolutional\_neural\_network. [Accessed: 31-Oct-2018]. \newline
[3] Ajolleyx, “Intel® Movidius™ Neural Compute Stick,” Intel® Software, 22-Aug-2018. [Online]. Available: https://software.intel.com/en-us/neural-compute-stick. [Accessed: 31-Oct-2018].

\section{Specific Requirements}
\subsection{External Interfaces}
\underline{Logitech Webcam}- This external tool will be able to take high definition pictures of the seeds at a rate of 14 seeds per second. This device can be inputted into a USB port in the laptop computer. This camera will need to be able to handle the throughput of taking a picture and transferring the data to the compute stick through a python interface within a second. \\
\underline{Movidium Neural Compute Stick} - The movidius neural compute stick is a lightweight and portable tool that can hold the trained neural network matrix which offers portable and lightweight classification which is invaluable to the system. The neural compute stick can be put into a usb port of the laptop. The neural compute stick should be able to transfer the accuracy rate the training step yields. The compute stick will need to be able to classify an image of at least 14 seeds given by the camera in under a second with high accuracy. The compute stick should also be able to output the image and classification to a database before the next image comes through it for classification. 


\subsection{Functions}
We will need to ensure that the images being taken are processed as they come in without overlap, and the system doesn’t get overwhelmed with images. One thing to keep in mind is to limit the process of gathering and classifying data to exactly a second as this is a good benchmark to work off of. Our workflow will work in the following order; first, the webcam will take an image of roughly 14 seeds moving down a conveyor belt, once the picture is taken it is then pre-processed, then it is brought through the neural network which will classify whether or not an off-type seed is present, the classification and image will then be transferred to another python program that will add it to another database, if the group does indeed contain an off-type seed we throw all those seeds into a bad pile. Keep in mind this whole process needs to be completed in one second.

\subsection{Usability Requirements}
Users will be required to set port locations on a laptop for the webcam, movidius Neural Net USB stick, other potential devices, and be able start and stop the system for each batch of approximately 25,000 seeds. The whole system should be mounted onto the already existing conveyor belt. The interface should be such that a user with basic computer understanding can start and stop the system.

\subsection{Performance Requirements}
Our device must be capable of signaling when an off-type seed is identified on the conveyor belt. Seeds will come down the conveyor belt at a rate of approximately 14 seeds per second. Assuming groups identified as containing an off-type seed are removed, the resulting pure seed should be 99.9\% percent accurate, so as to contain almost only pure seed. Our device will be allowed to send some number of false positives. False positives will be allowed so long as no more than 10\% of pure seed is classified as off-type by our system. As a stretch goal, we may include some number of the following features. Conveyor control may be used so that the conveyor could stop upon identifying an off-type seed. This may also be used to more accurately take pictures or reduce the speed at which seeds traverse across the camera's field of vision. Our system may also send abstract coordinates to a specified source in order to automate the off-type seed removal process.

\subsection{Logical Database Requirements}
Two major databases will be necessary for the implementation of this system, a training database, and a testing database. The training database will need to contain a simple index, an image of a single seed, and whether that seed is an on or off-type seed. This database will only be needed for the training process and will not need to be accessed during actual system use. It should be capable of being accessed at a speed that makes training achievable. The training database will be partitioned into 2 parts, with 75\% of the database being the actual training set, and the remaining 25\% being for validation. The testing database will consist of a simple index, and image that was classified, and whether that image was classified as an on or off-type seed by the system. We can then manually check each of these seeds to add additional data points to the training set, and ensure that our system is working properly. This testing database will need to be updated by our system as it classifies seeds in real time. We will then utilize the testing database for future use in our training database, to increase classification accuracy in future tests. 

\subsection{Design Constraints}
Our system will be constrained to fit around the conveyor apparatus and it needs to work in tangent to the already already established method of classification. Essentially, we must be able to replace the microscope traditionally used by the assistants with a webcam and perform the same functionality. We must also ensure the portability and scalability of the system. In terms of algorithmic constraints, there are very few. One thing to keep in mind is the method of collecting and pre-processing the data. We realize that the window of frame for the objects is a very tiny area we must ensure that our camera is set to the right zoom and focal length for all scenarios to ensure the system doesn’t get confused and to maintain consistency. 

\subsection{Software System Attributes}
\underline{Reliability} - The system will have to go through a series of pre-planned tests both internally by the group and externally through a trusted observer. Once these tests have been passed, a real demo will be given to the client to ensure that it meets their specifications.\\ 
\underline{Availability} - Our team will need to ensure that the system can be restarted and working if any bug occurs. Moreover, we will need to be able to give the user checkpoints at specified seed counts in order to notify them of the status of the system. If anything goes wrong with the system the user should be able to restart it and the system should pick back up from where it left off.\\ 
\underline{Security} - Our system will be housed as an isolated system where the only access to the outside world will be to an external database. This database will be password protected and hosted locally on an external hard drive capable of holding a vast amount of data. Using hashing algorithms such as SHA-256 or RSA we can protect the database and decrypt it with our public key. As the physical system will live with the client it will be up to them to protect it. Our codebase however will be publically available on GitHub, however without the training data the algorithms we put on GitHub will be useless. Our primary objective will be to protect the databases under many layers of encryption.\\
\underline{Maintainability} - Bugs related to the system should be vetted out before the product release. The system should also have the ability to be maintained by non engineers, meaning it should be simple to use. In the aforementioned availability section we mentioned that there will be a checkpoint notification given to the user, any information regarding maintenance of the system should be conveyed through this message. \\
\underline{Portability} - As this project will mostly be done through a linux portal and using the python programming language, we will provide a readme.md as well as a requirements.txt so that future implementations can be easily done, this will also ensure scalability. 


\subsection{Supporting Information}
The system will take in preprocessed images of at least 14 seeds per second. It will then classify the following image, if it recognizes any off type seeds it will flag that image as one that contains an offtype seed and upload both the picture and classification to a database. Users will have access to the database which will allow them to manually verify if the image does indeed contain an offtype seed. Users will not be given access to the internal code in order to avoid any tampering, any further information required by them can be implemented by the developers. 

\subsection{Verification}
In order to verify our system we have to test each part and see what its limitations are. Our computer vision algorithms will be tested with a small amount of seeds to test if it actually works, then move on to larger samples to test limitation. The sample sizes would start at our desired amount 14-15 seeds per second and then increase until failures become constant. This way we can see how our system can handle an accidental large amount of seeds and if it will fail at identifying if that happens. The second part we will test is the database and neural net identification. To test this we will be having the neural network identify images as good or bad seeds and see if it matches our accuracy of 99\%. Then we will see how accurate and quickly it is able to identify the images when many are sent rapidly. This will allow us to see the limitations of our neural network and show where it could potentially fail. In order to reduce errors in classification, we need to see how fast seeds goes through the conveyor and calculate the window of latency for classification and how far the seeds move down the belt. Finally our outputted database from the testing data should be manually verified to test the real world application of our systems. Manual checking is needed because the data points don’t have any labels as opposed to the training and validation sets. 

\section{Appendices}
\subsection{Assumptions and Dependencies}
Our system will be dependant upon the sorting mechanism capable of interpreting our signal in order to actually sort the seeds that pass through. Our system is responsible only for generating a signal indicating that an off-type seed has been identified. It will be assumed that such a device, or a human capable of removing off-type seeds will be working in conjunction with our device in order to create a working system.

\subsection{Acronyms and Abbreviations}
CNN: Stands for Convolutional Neural Network, this is a deep learning algorithm that trains a neural network.

\pagebreak
\section{Seed Project Gantt Chart}
\newcommand{\elemzero}{elem0}
\newcommand{\elemone}{elem1}
\newcommand{\elemtwo}{elem2}
\newcommand{\elemthree}{elem3}
\newcommand{\elemfour}{elem4}
\newcommand{\elemfive}{elem5}
\newcommand{\elemsix}{elem6}
\newcommand{\elemseven}{elem7}
\newcommand{\elemeight}{elem8}
\newcommand{\elemnine}{elem9}

\begin{ganttchart}{1}{20}
\gantttitlelist{"winter","spring"}{10} \\
\gantttitlelist{1,...,20}{1} \\
\ganttbar{Gather Training Images}{1}{2} \\
\ganttbar{Research Neural Networks}{3}{4} \\
\ganttbar{Code CNN}{5}{6} \\
\ganttbar{Train CNN}{7}{8} \\

\ganttbar{Work on Database}{9}{10} \\
\ganttbar{Verify Results}{11}{12} \\
\ganttbar{Reconvene with Client}{13}{14} \\
\ganttbar{Finalize Design}{15}{16} \\
\ganttbar{Prepare for Capstone Presentation}{17}{18} \\
\ganttbar{Attend Engineering Convention}{19}{20} \\
\ganttlink{\elemzero}{\elemone}
\ganttlink{\elemzero}{\elemthree}
\ganttlink{\elemone}{\elemtwo}
\ganttlink{\elemtwo}{\elemthree}
\ganttlink{\elemthree}{\elemfour}
\ganttlink{\elemfour}{\elemfive}
\ganttlink{\elemfive}{\elemsix}
\ganttlink{\elemfive}{\elemseven}
\ganttlink{\elemsix}{\elemseven}
\ganttlink{\elemseven}{\elemeight}
\ganttlink{\elemeight}{\elemnine}
\end{ganttchart}


\end{document}
